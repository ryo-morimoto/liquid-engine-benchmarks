# Full Benchmark Workflow
#
# Runs comprehensive benchmarks on:
# - Push to main branch
# - Monthly schedule (1st of each month)
# - Manual trigger
#
# Matrix is dynamically generated from leb.config.json.
# Security: All shell inputs use environment variables, no untrusted user input.

name: Benchmark

on:
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'scenarios/**'
      - 'leb.config.json'
      - '.github/workflows/benchmark.yml'

  schedule:
    # Monthly: 1st day at 00:00 UTC
    - cron: '0 0 1 * *'

  workflow_dispatch:
    inputs:
      scale:
        description: 'Data scale'
        required: true
        default: 'medium'
        type: choice
        options: [small, medium, large]
      iterations:
        description: 'Number of iterations'
        required: true
        default: '100'
        type: string

concurrency:
  group: benchmark-${{ github.ref }}
  cancel-in-progress: false

jobs:
  # Generate benchmark matrix from leb.config.json
  setup:
    name: Setup Matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.gen.outputs.matrix }}
      timestamp: ${{ steps.gen.outputs.timestamp }}
    steps:
      - uses: actions/checkout@v4

      - name: Generate matrix
        id: gen
        run: |
          matrix=$(jq -c '{
            include: [
              .libraries[] |
              .versions[] as $v |
              {
                adapter: .name,
                package: .package,
                lib_version: $v,
                lang: .lang
              }
            ]
          } + {
            runtimes: .runtimes
          }' leb.config.json)
          echo "matrix=$matrix" >> "$GITHUB_OUTPUT"
          echo "timestamp=$(date -u +%Y%m%d-%H%M%S)" >> "$GITHUB_OUTPUT"

  # Run full benchmark for each adapter/version
  bench:
    name: Bench ${{ matrix.adapter }}@${{ matrix.lib_version }}
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.setup.outputs.matrix) }}

    env:
      SCALE: ${{ inputs.scale || 'medium' }}
      ITERATIONS: ${{ inputs.iterations || '100' }}
      ADAPTER: ${{ matrix.adapter }}
      PACKAGE: ${{ matrix.package }}
      LIB_VERSION: ${{ matrix.lib_version }}
      LANG: ${{ matrix.lang }}
      PHP_VERSION: ${{ fromJson(needs.setup.outputs.matrix).runtimes.php }}
      RUBY_VERSION: ${{ fromJson(needs.setup.outputs.matrix).runtimes.ruby }}

    steps:
      - uses: actions/checkout@v4

      - uses: oven-sh/setup-bun@v2

      - name: Cache Bun
        uses: actions/cache@v4
        with:
          path: ~/.bun/install/cache
          key: bun-${{ hashFiles('bun.lock') }}

      - run: bun install --frozen-lockfile

      # Seed benchmark database
      - name: Seed database
        run: bun src/run.ts prepare

      # PHP setup
      - name: Setup PHP
        if: matrix.lang == 'php'
        uses: shivammathur/setup-php@v2
        with:
          php-version: ${{ env.PHP_VERSION }}
          extensions: mbstring
          tools: composer:v2

      - name: Cache Composer
        if: matrix.lang == 'php'
        uses: actions/cache@v4
        with:
          path: vendor
          key: composer-${{ matrix.package }}-${{ matrix.lib_version }}

      - name: Install PHP dependencies
        if: matrix.lang == 'php'
        run: |
          bun src/run.ts setup php
          composer require "${PACKAGE}:${LIB_VERSION}" --no-interaction

      # Ruby setup
      - name: Setup Ruby
        if: matrix.lang == 'ruby'
        uses: ruby/setup-ruby@v1
        with:
          ruby-version: ${{ env.RUBY_VERSION }}

      - name: Cache Bundler
        if: matrix.lang == 'ruby'
        uses: actions/cache@v4
        with:
          path: vendor/bundle
          key: bundler-${{ matrix.package }}-${{ matrix.lib_version }}

      - name: Install Ruby dependencies
        if: matrix.lang == 'ruby'
        run: |
          bun src/run.ts setup ruby
          bundle config set --local path vendor/bundle
          sed -i "s/gem \"${PACKAGE}\"/gem \"${PACKAGE}\", \"${LIB_VERSION}\"/" Gemfile
          bundle install

      # Run full benchmark for all scenarios
      - name: Run benchmark
        run: |
          mkdir -p results
          bun src/run.ts list scenarios | while read scenario; do
            echo "Running: ${ADAPTER} Ã— ${scenario}"
            output_file="results/${ADAPTER}_$(echo "${scenario}" | tr '/' '_').json"
            bun src/run.ts bench "${ADAPTER}" "${scenario}" \
              -s "${SCALE}" \
              -i "${ITERATIONS}" \
              -w 10 \
              -o "${output_file}" || echo "Failed: ${scenario}"
          done

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.adapter }}-${{ matrix.lib_version }}
          path: results/
          retention-days: 90

  # Aggregate all results
  aggregate:
    name: Aggregate Results
    needs: [setup, bench]
    if: always() && !cancelled()
    runs-on: ubuntu-latest

    env:
      TIMESTAMP: ${{ needs.setup.outputs.timestamp }}
      SCALE: ${{ inputs.scale || 'medium' }}
      ITERATIONS: ${{ inputs.iterations || '100' }}
      EVENT_NAME: ${{ github.event_name }}

    steps:
      - uses: actions/checkout@v4

      - name: Download all results
        uses: actions/download-artifact@v4
        with:
          path: all-results
          pattern: results-*
          merge-multiple: true

      - name: Create summary
        run: |
          {
            echo "# Benchmark Results - ${TIMESTAMP}"
            echo ""
            echo "## Configuration"
            echo "- Scale: ${SCALE}"
            echo "- Iterations: ${ITERATIONS}"
            echo "- Trigger: ${EVENT_NAME}"
            echo ""
            echo "## Results"
            echo ""

            total=$(find all-results -name '*.json' 2>/dev/null | wc -l)
            success=$(find all-results -name '*.json' -exec grep -l '"success": true' {} \; 2>/dev/null | wc -l)

            echo "- Total: ${total}"
            echo "- Success: ${success}"
            echo "- Failed: $((total - success))"
          } | tee summary.md >> "$GITHUB_STEP_SUMMARY"

      - name: Upload aggregated results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-${{ needs.setup.outputs.timestamp }}
          path: |
            all-results/
            summary.md
          retention-days: 90
